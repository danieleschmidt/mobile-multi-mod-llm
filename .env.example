# Mobile Multi-Modal LLM Environment Configuration
# Copy this file to .env and configure for your environment

# ==========================================
# Development Configuration
# ==========================================

# Python environment
PYTHONPATH=./src
PYTHONDONTWRITEBYTECODE=1
PYTHONUNBUFFERED=1

# Development mode
DEBUG=1
DEVELOPMENT_MODE=true
LOG_LEVEL=DEBUG

# ==========================================
# Model Configuration
# ==========================================

# Model paths
MODEL_CACHE_DIR=./models
CHECKPOINT_DIR=./checkpoints
EXPORT_DIR=./exports

# Model settings
DEFAULT_MODEL_SIZE=35MB
DEFAULT_QUANTIZATION=INT2
MAX_SEQUENCE_LENGTH=512
IMAGE_SIZE=224

# ==========================================
# Training Configuration
# ==========================================

# Training settings
BATCH_SIZE=32
LEARNING_RATE=1e-4
NUM_EPOCHS=100
GRADIENT_ACCUMULATION_STEPS=4
MIXED_PRECISION=true

# Data paths
TRAIN_DATA_PATH=./data/train
VAL_DATA_PATH=./data/val
TEST_DATA_PATH=./data/test
CALIBRATION_DATA_PATH=./data/calibration

# Experiment tracking
WANDB_PROJECT=mobile-multimodal-llm
WANDB_ENTITY=your-wandb-username
WANDB_API_KEY=your-wandb-api-key
MLFLOW_TRACKING_URI=./mlruns

# ==========================================
# Hardware Configuration
# ==========================================

# Device settings
CUDA_VISIBLE_DEVICES=0
USE_MIXED_PRECISION=true
DATALOADER_NUM_WORKERS=4

# Mobile hardware simulation
SIMULATE_MOBILE_CONSTRAINTS=false
MOBILE_MEMORY_LIMIT_MB=4096
MOBILE_COMPUTE_BUDGET_GFLOPS=100

# ==========================================
# Export Configuration
# ==========================================

# Android export
ANDROID_NDK_PATH=/opt/android-ndk
HEXAGON_SDK_PATH=/opt/hexagon-sdk
EXPORT_ANDROID_TFLITE=true
EXPORT_ANDROID_DLC=true

# iOS export
XCODE_PATH=/Applications/Xcode.app
EXPORT_IOS_COREML=true
EXPORT_IOS_MLPACKAGE=true

# Cross-platform export
EXPORT_ONNX=true
EXPORT_TORCHSCRIPT=true

# ==========================================
# Testing Configuration
# ==========================================

# Test settings
RUN_SLOW_TESTS=false
RUN_HARDWARE_TESTS=false
TEST_DATA_SIZE=small
BENCHMARK_ITERATIONS=10

# Performance thresholds
MAX_INFERENCE_TIME_MS=15
MIN_ACCURACY_THRESHOLD=0.90
MAX_MODEL_SIZE_MB=35

# ==========================================
# Security Configuration
# ==========================================

# API keys and secrets (DO NOT commit real values)
HUGGINGFACE_TOKEN=your-hf-token-here
OPENAI_API_KEY=your-openai-key-here

# Security scanning
ENABLE_SECURITY_SCANNING=true
BANDIT_CONFIG_PATH=.bandit
SAFETY_API_KEY=your-safety-api-key

# ==========================================
# CI/CD Configuration
# ==========================================

# GitHub Actions
GITHUB_TOKEN=your-github-token
GITHUB_REPOSITORY=terragon-labs/mobile-multimodal-llm

# Release configuration
ENABLE_AUTO_RELEASE=false
RELEASE_BRANCH=main
PRE_RELEASE=true

# ==========================================
# Monitoring Configuration
# ==========================================

# Observability
ENABLE_TELEMETRY=true
TELEMETRY_ENDPOINT=http://localhost:4317
JAEGER_AGENT_HOST=localhost
JAEGER_AGENT_PORT=6831

# Metrics
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
ENABLE_PERFORMANCE_MONITORING=true

# Health checks
HEALTH_CHECK_INTERVAL=30
HEALTH_CHECK_TIMEOUT=5

# ==========================================
# Documentation Configuration
# ==========================================

# MkDocs
DOCS_PORT=8000
DOCS_DEV_ADDR=localhost:8000
ENABLE_SEARCH=true

# API documentation
SWAGGER_ENABLED=true
REDOC_ENABLED=true

# ==========================================
# Development Tools
# ==========================================

# Jupyter
JUPYTER_PORT=8888
JUPYTER_TOKEN=
JUPYTER_PASSWORD=

# TensorBoard
TENSORBOARD_PORT=6006
TENSORBOARD_LOGDIR=./tensorboard_logs

# Code quality
BLACK_LINE_LENGTH=88
ISORT_PROFILE=black
MYPY_STRICT=true

# ==========================================
# Advanced Configuration
# ==========================================

# Quantization
CALIBRATION_DATASET_SIZE=1000
QUANTIZATION_BACKEND=neural_compressor
INT2_CALIBRATION_METHOD=histogram

# Neural Architecture Search
NAS_SEARCH_SPACE=mobile_optimized
NAS_STRATEGY=differentiable
NAS_HARDWARE_CONSTRAINTS=snapdragon_8gen3

# Memory optimization
ENABLE_GRADIENT_CHECKPOINTING=true
ENABLE_ACTIVATION_CHECKPOINTING=true
MAX_MEMORY_USAGE_GB=16

# Distributed training
DISTRIBUTED_BACKEND=nccl
WORLD_SIZE=1
RANK=0
MASTER_ADDR=localhost
MASTER_PORT=23456

# ==========================================
# Platform-Specific Configuration
# ==========================================

# Docker
DOCKER_BUILDKIT=1
COMPOSE_PROJECT_NAME=mobile-mm-llm

# Cloud providers
AWS_REGION=us-west-2
GCP_PROJECT_ID=your-gcp-project
AZURE_SUBSCRIPTION_ID=your-azure-subscription

# ==========================================
# Debugging Configuration
# ==========================================

# Debug settings
CUDA_LAUNCH_BLOCKING=0
TORCH_SHOW_CPP_STACKTRACES=1
TORCH_USE_CUDA_DSA=0

# Profiling
ENABLE_PROFILING=false
PROFILER_OUTPUT_DIR=./profiles
PROFILE_MEMORY=false

# Logging
LOG_FORMAT=json
LOG_FILE=./logs/app.log
LOG_ROTATION=daily
LOG_RETENTION_DAYS=30